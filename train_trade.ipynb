{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=2048, dataset_path='./cifar10', epoch=30000, imgc=3, imgsz=84, k_qry=15, k_spt=1, meta_lr=0.001, n_way=5, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "=> no checkpoint found at 'mamltradesrseps2self1.pt'\n",
      "Meta(\n",
      "  (net): Learner(\n",
      "    conv2d:(ch_in:3, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:1, padding:0)\n",
      "    flatten:()\n",
      "    linear:(in:800, out:5)\n",
      "    \n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.cuda.FloatTensor of size 32x3x3x3 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.cuda.FloatTensor of size 32x32x3x3 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (6): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (7): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (8): Parameter containing: [torch.cuda.FloatTensor of size 32x32x3x3 (GPU 0)]\n",
      "        (9): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (10): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (11): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (12): Parameter containing: [torch.cuda.FloatTensor of size 32x32x3x3 (GPU 0)]\n",
      "        (13): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (14): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (15): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (16): Parameter containing: [torch.cuda.FloatTensor of size 5x800 (GPU 0)]\n",
      "        (17): Parameter containing: [torch.cuda.FloatTensor of size 5 (GPU 0)]\n",
      "    )\n",
      "    (vars_bn): ParameterList(\n",
      "        (0): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (6): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "        (7): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 32901\n",
      "shuffle DB :train, b:10000, 5-way, 1-shot, 15-query, resize:84\n",
      "shuffle DB :test, b:100, 5-way, 1-shot, 15-query, resize:84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renwang/.local/lib/python3.7/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \ttraining acc: [0.17333333 0.22333333 0.23333333 0.24333333 0.25       0.24333333]\n",
      "step: 0 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renwang/META/MetaFT.py:375: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  corr_ind = (torch.eq(pred_q, y_qry) == True).nonzero()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: [0.1965 0.2351 0.2408 0.2429 0.2417 0.2428 0.2432 0.2439 0.2444 0.2451\n",
      " 0.2454]\n",
      "Test acc_adv: [0.0008   0.002533 0.0028   0.0028   0.002533 0.002934 0.0028   0.003067\n",
      " 0.0028   0.0028   0.003067]\n",
      "Test acc_adv_prior: [0.003874 0.01078  0.01132  0.01107  0.01028  0.011955 0.01127  0.01234\n",
      " 0.01117  0.011246 0.01224 ]\n",
      "step: 30 \ttraining acc: [0.18333333 0.36333333 0.35666667 0.37       0.35666667 0.36333333]\n",
      "step: 30 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 60 \ttraining acc: [0.19       0.28666667 0.32       0.31       0.31333333 0.32333333]\n",
      "step: 60 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 90 \ttraining acc: [0.19333333 0.32666667 0.34666667 0.36       0.38333333 0.38666667]\n",
      "step: 90 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 120 \ttraining acc: [0.23       0.24333333 0.29333333 0.30666667 0.32       0.31      ]\n",
      "step: 120 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 150 \ttraining acc: [0.19333333 0.3        0.31       0.30666667 0.29666667 0.32      ]\n",
      "step: 150 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 180 \ttraining acc: [0.27       0.26666667 0.25333333 0.24666667 0.24333333 0.24      ]\n",
      "step: 180 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import  torch, os\n",
    "import  numpy as np\n",
    "from    MiniImagenet import MiniImagenet\n",
    "import  scipy.stats\n",
    "from    torch.utils.data import DataLoader\n",
    "from    torch.optim import lr_scheduler\n",
    "import  random, sys, pickle\n",
    "import  argparse\n",
    "import skimage.transform\n",
    "\n",
    "from LoadUnlableData import UnlabData\n",
    "\n",
    "#from MAMLROBUST import Meta\n",
    "# import dataset_input\n",
    "# import utilities\n",
    "import time\n",
    "from MetaFT import Meta\n",
    "\n",
    "\n",
    "\n",
    "def mean_confidence_interval(accs, confidence=0.95):\n",
    "    n = accs.shape[0]\n",
    "    m, se = np.mean(accs), scipy.stats.sem(accs)\n",
    "    h = se * scipy.stats.t._ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, h\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    torch.manual_seed(222)\n",
    "    torch.cuda.manual_seed_all(222)\n",
    "    np.random.seed(222)\n",
    "\n",
    "    print(args)\n",
    "\n",
    "    config = [\n",
    "        ('conv2d', [32, 3, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 1, 0]),\n",
    "        ('flatten', []),\n",
    "        ('linear', [args.n_way, 32 * 5 * 5])\n",
    "    ]\n",
    "\n",
    "    device = torch.device('cuda:0')\n",
    "    maml = Meta(args, config, device).to(device)\n",
    "#     maml = Meta(args, config)\n",
    "\n",
    "    start_epoch = 0\n",
    "    start_step = 0\n",
    "    filename = 'mamltradesrseps2self1.pt'\n",
    "    #maml = Meta(args, config).to(device)\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        start_step = checkpoint['step']\n",
    "        maml.net.load_state_dict(checkpoint['state_dict'])\n",
    "        #maml = maml.to(device)\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "        #maml = Meta(args, config).to(device)\n",
    "\n",
    "\n",
    "\n",
    "    tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "    num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "    print(maml)\n",
    "    print('Total trainable tensors:', num)\n",
    "\n",
    "    # batchsz here means total episode number\n",
    "    mini = MiniImagenet('../', mode='train', n_way=args.n_way, k_shot=args.k_spt,\n",
    "                        k_query=args.k_qry,\n",
    "                        batchsz=10000, resize=args.imgsz)\n",
    "    mini_test = MiniImagenet('../', mode='test', n_way=args.n_way, k_shot=args.k_spt,\n",
    "                             k_query=args.k_qry,\n",
    "                             batchsz=100, resize=args.imgsz)\n",
    "    \n",
    "    tinyimg = UnlabData()\n",
    "    batchsiz = 20\n",
    "    \n",
    "    \n",
    "\n",
    "    for epoch in range(start_epoch, args.epoch//10000):\n",
    "        # fetch meta_batchsz num of episode each time\n",
    "        db = DataLoader(mini, args.task_num, shuffle=True, num_workers=0, pin_memory=True)\n",
    "        \n",
    "            \n",
    "\n",
    "        for step, (x_spt, y_spt, x_qry, y_qry) in enumerate(db):\n",
    "#             if step == 1:\n",
    "#                 t = time.perf_counter()\n",
    "#             if step == 499:\n",
    "#                 ExecTime = time.perf_counter() - t\n",
    "#                 print(ExecTime)\n",
    "            x_unlab = torch.zeros((args.task_num, args.n_way, batchsiz, 3, 84, 84))\n",
    "\n",
    "            x_spt, y_spt, x_qry, y_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "            \n",
    "            for i in range(args.task_num):\n",
    "                for j in range(args.n_way):\n",
    "                    index = y_spt[i][j].cpu().numpy()\n",
    "                    temp_train = tinyimg.train_data[index].get_next_batch(batchsiz,multiple_passes=True)\n",
    "                    \n",
    "                    x_unlab[i][j]= torch.from_numpy(temp_train.astype(np.float32))\n",
    "            x_unlab = x_unlab.to(device)\n",
    "            \n",
    "\n",
    "            accs, accs_adv = maml(x_spt, y_spt, x_qry, y_qry, x_unlab)\n",
    "\n",
    "            if step % 30 == 0:\n",
    "                print('step:', step, '\\ttraining acc:', accs)\n",
    "                print('step:', step, '\\ttraining acc_adv:', accs_adv)\n",
    "                state = {'epoch': epoch, 'step': step, 'state_dict': maml.net.state_dict()}\n",
    "                #torch.save(state, 'mamltradesrseps2self.pt')\n",
    "\n",
    "            if step % 500 == 0 or step % 2500 == 0:  # evaluation\n",
    "                db_test = DataLoader(mini_test, 1, shuffle=True, num_workers=0, pin_memory=True)\n",
    "                accs_all_test = []\n",
    "                accsadv_all_test = []\n",
    "                accsadvpr_all_test = []\n",
    "\n",
    "                for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                    x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                                 x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "#                     x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0), y_spt.squeeze(0), \\\n",
    "#                                                  x_qry.squeeze(0), y_qry.squeeze(0)\n",
    "\n",
    "                    accs, accs_adv, accs_adv_prior = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                    accs_all_test.append(accs)\n",
    "                    accsadv_all_test.append(accs_adv)\n",
    "                    accsadvpr_all_test.append(accs_adv_prior)\n",
    "\n",
    "                # [b, update_step+1]\n",
    "                accs = np.array(accs_all_test).mean(axis=0).astype(np.float16)\n",
    "                accs_adv = np.array(accsadv_all_test).mean(axis=0).astype(np.float16)\n",
    "                accs_adv_prior = np.array(accsadvpr_all_test).mean(axis=0).astype(np.float16)\n",
    "                print('Test acc:', accs)\n",
    "                print('Test acc_adv:', accs_adv)\n",
    "                print('Test acc_adv_prior:', accs_adv_prior)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    argparser = argparse.ArgumentParser()\n",
    "    argparser.add_argument('--epoch', type=int, help='epoch number', default=30000)\n",
    "    argparser.add_argument('--n_way', type=int, help='n way', default=5)\n",
    "    argparser.add_argument('--k_spt', type=int, help='k shot for support set', default=1)\n",
    "    argparser.add_argument('--k_qry', type=int, help='k shot for query set', default=15)\n",
    "    argparser.add_argument('--imgsz', type=int, help='imgsz', default=84)\n",
    "    argparser.add_argument('--imgc', type=int, help='imgc', default=3)\n",
    "    argparser.add_argument('--task_num', type=int, help='meta batch size, namely task num', default=4)\n",
    "    argparser.add_argument('--meta_lr', type=float, help='meta-level outer learning rate', default=1e-3)\n",
    "    argparser.add_argument('--update_lr', type=float, help='task-level inner update learning rate', default=0.01)\n",
    "    argparser.add_argument('--update_step', type=int, help='task-level inner update steps', default=5)\n",
    "    argparser.add_argument('--update_step_test', type=int, help='update steps for finetunning', default=10)\n",
    "    argparser.add_argument('--batch-size', default=2048, type=int, help='batch size')\n",
    "    argparser.add_argument('--dataset-path', default = './cifar10', type=str, help='dataset folder')\n",
    "    \n",
    "    #argparser.add_argument('--fast', action=\"store_true\", help='whether to use fgsm')\n",
    "\n",
    "    args = argparser.parse_args(args=[])\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
