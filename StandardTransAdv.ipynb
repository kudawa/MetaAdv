{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch, os\n",
    "import  numpy as np\n",
    "from    MiniImagenet import MiniImagenet\n",
    "import  scipy.stats\n",
    "from    torch.utils.data import DataLoader\n",
    "from    torch.optim import lr_scheduler\n",
    "import  random, sys, pickle\n",
    "import  argparse\n",
    "\n",
    "from    torch import nn\n",
    "from    torch import optim\n",
    "from    torch.nn import functional as F\n",
    "\n",
    "from    learner import Learner\n",
    "# from    copy import deepcopy\n",
    "from attack import PGD\n",
    "\n",
    "\n",
    "from StandardTrans import Transfer\n",
    "from LoadDataST import ImagenetMini\n",
    "\n",
    "\n",
    "\n",
    "def mean_confidence_interval(accs, confidence=0.95):\n",
    "    n = accs.shape[0]\n",
    "    m, se = np.mean(accs), scipy.stats.sem(accs)\n",
    "    h = se * scipy.stats.t._ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, h\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "#     torch.manual_seed(222)\n",
    "#     torch.cuda.manual_seed_all(222)\n",
    "#     np.random.seed(222)\n",
    "\n",
    "    print(args)\n",
    "\n",
    "    config = [\n",
    "        ('conv2d', [32, 3, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 1, 0]),\n",
    "        ('flatten', []),\n",
    "        ('linear', [64, 32 * 5 * 5])\n",
    "    ]\n",
    "\n",
    "    device = torch.device('cuda:4')\n",
    "    \n",
    "    start_epoch = 0\n",
    "    start_step = 0\n",
    "    filename = 'standardtrainadv.pt'\n",
    "    transferlearn = Learner(config, args.imgc, args.imgsz).to(device)\n",
    "#     trans_optim = optim.Adam(transferlearn.parameters(), lr=args.meta_lr)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_step = checkpoint['step']\n",
    "        transferlearn.load_state_dict(checkpoint['state_dict'])\n",
    "        #maml = maml.to(device)\n",
    "        print(\"=> loaded checkpoint '{}' (step {})\"\n",
    "                  .format(filename, checkpoint['step']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    trans_optim = torch.optim.SGD(transferlearn.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(trans_optim, milestones=[30, 85, 108], gamma=0.1)\n",
    "    #trans_optim = Lamb(transferlearn.parameters(), lr=0.01, weight_decay=1e-4, betas=(.9, .999), adam=False)\n",
    "    tmp = filter(lambda x: x.requires_grad, transferlearn.parameters())\n",
    "    num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "    print(transferlearn)\n",
    "    print(type(transferlearn))\n",
    "    print('Total trainable tensors:', num)\n",
    "\n",
    "    # batchsz here means total episode number\n",
    "#     mini = MiniImagenet('../../../dataset/', mode='train', n_way=args.n_way, k_shot=5,\n",
    "#                         k_query=5,\n",
    "#                         batchsz=10000, resize=args.imgsz)\n",
    "    mini = ImagenetMini('../../../dataset/', mode='train',\n",
    "                        batchsz=10000, resize=args.imgsz)\n",
    "    mini_test = MiniImagenet('../../../dataset/', mode='test', n_way=5, k_shot=1,\n",
    "                             k_query=args.k_qry,\n",
    "                             batchsz=100, resize=args.imgsz)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#     for epoch in range(args.epoch//10000):\n",
    "#         # fetch meta_batchsz num of episode each time\n",
    "#         db = DataLoader(mini, args.task_num, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    at = PGD(eps=2 / 255.0, sigma=2 / 255.0, nb_iter=10)\n",
    "\n",
    "    for step in range(start_step, 30000):\n",
    "\n",
    "\n",
    "        x, y = mini.loading_data.get_next_batch(64, multiple_passes=True, reshuffle_after_pass=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        x_sq = x.to(device)\n",
    "        y_sq = y.to(device)\n",
    "\n",
    "        querysz = x_sq.size(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        trans_optim.zero_grad()\n",
    "\n",
    "\n",
    "        adv_inp = at.attack(transferlearn, transferlearn.parameters(), x_sq, y_sq)\n",
    "        trans_optim.zero_grad()\n",
    "        transferlearn.train()\n",
    "        logits = transferlearn(adv_inp, vars=None, bn_training=True)\n",
    "        loss = criterion(logits, y_sq)\n",
    "\n",
    "#         acc = torch_accuracy(pred, label, (1,))\n",
    "#         advacc = acc[0].item()\n",
    "#         advloss = loss.item()\n",
    "        (loss * 1.0).backward()\n",
    "        trans_optim.step()\n",
    "    \n",
    "        trans_optim.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        logits = transferlearn(x_sq, vars=None, bn_training=True)\n",
    "        loss = criterion(logits, y_sq)\n",
    "        with torch.no_grad():\n",
    "            pred = F.softmax(logits, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred, y_sq).sum().item()\n",
    "\n",
    "\n",
    "        trans_optim.zero_grad()\n",
    "        loss.backward()\n",
    "        trans_optim.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "\n",
    "\n",
    "        accs = np.array(correct) / (querysz)\n",
    "\n",
    "        if step % 30 == 0:                   \n",
    "            print('step:', step, '\\ttraining acc:', accs)\n",
    "#                 print('step:', step, '\\ttraining acc_adv:', accs_adv)\n",
    "            state = {'step': step, 'state_dict': transferlearn.state_dict()}\n",
    "            torch.save(state, 'standardtrainadv.pt')\n",
    "\n",
    "        if step % 500 == 0:  # evaluation\n",
    "\n",
    "            db_test = DataLoader(mini_test, 1, shuffle=True, num_workers=0, pin_memory=True)\n",
    "            accs_all_test = []\n",
    "            accsadv_all_test = []\n",
    "            accsadvpr_all_test = []\n",
    "            transfertst = Transfer(args, config).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                             x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "\n",
    "                accs, accs_adv, accs_adv_prior = transfertst.finetunning(x_spt, y_spt, x_qry, y_qry, transferlearn)\n",
    "                accs_all_test.append(accs)\n",
    "                accsadv_all_test.append(accs_adv)\n",
    "                accsadvpr_all_test.append(accs_adv_prior)\n",
    "\n",
    "            # [b, update_step+1]\n",
    "            accs = np.array(accs_all_test).mean(axis=0).astype(np.float16)\n",
    "            accs_adv = np.array(accsadv_all_test).mean(axis=0).astype(np.float16)\n",
    "            accs_adv_prior = np.array(accsadvpr_all_test).mean(axis=0).astype(np.float16)\n",
    "            print('Test acc:', accs)\n",
    "            print('Test acc_adv:', accs_adv)\n",
    "            print('Test acc_adv_prior:', accs_adv_prior)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    argparser = argparse.ArgumentParser()\n",
    "    argparser.add_argument('--epoch', type=int, help='epoch number', default=100000)\n",
    "    argparser.add_argument('--n_way', type=int, help='n way', default=5)\n",
    "    argparser.add_argument('--k_spt', type=int, help='k shot for support set', default=1)\n",
    "    argparser.add_argument('--k_qry', type=int, help='k shot for query set', default=15)\n",
    "    argparser.add_argument('--imgsz', type=int, help='imgsz', default=84)\n",
    "    argparser.add_argument('--imgc', type=int, help='imgc', default=3)\n",
    "    argparser.add_argument('--task_num', type=int, help='meta batch size, namely task num', default=1)\n",
    "    argparser.add_argument('--meta_lr', type=float, help='meta-level outer learning rate', default=1e-3)\n",
    "    argparser.add_argument('--update_lr', type=float, help='task-level inner update learning rate', default=0.01)\n",
    "    argparser.add_argument('--update_step', type=int, help='task-level inner update steps', default=5)\n",
    "    argparser.add_argument('--update_step_test', type=int, help='update steps for finetunning', default=10)\n",
    "    \n",
    "    #argparser.add_argument('--fast', action=\"store_true\", help='whether to use fgsm')\n",
    "\n",
    "    args = argparser.parse_args(args=[])\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
