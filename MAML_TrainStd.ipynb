{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epoch=60000, imgc=3, imgsz=84, k_qry=15, k_spt=1, meta_lr=0.001, n_way=5, task_num=4, update_lr=0.01, update_step=5, update_step_test=10)\n",
      "=> loading checkpoint 'mamleps4.pt'\n",
      "=> loaded checkpoint 'mamleps4.pt' (epoch 0)\n",
      "Meta(\n",
      "  (net): Learner(\n",
      "    conv2d:(ch_in:3, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:2, padding:0)\n",
      "    conv2d:(ch_in:32, ch_out:32, k:3x3, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(32,)\n",
      "    max_pool2d:(k:2, stride:1, padding:0)\n",
      "    flatten:()\n",
      "    linear:(in:800, out:5)\n",
      "    \n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.cuda.FloatTensor of size 32x3x3x3 (GPU 3)]\n",
      "        (1): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (2): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (3): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (4): Parameter containing: [torch.cuda.FloatTensor of size 32x32x3x3 (GPU 3)]\n",
      "        (5): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (6): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (7): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (8): Parameter containing: [torch.cuda.FloatTensor of size 32x32x3x3 (GPU 3)]\n",
      "        (9): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (10): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (11): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (12): Parameter containing: [torch.cuda.FloatTensor of size 32x32x3x3 (GPU 3)]\n",
      "        (13): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (14): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (15): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (16): Parameter containing: [torch.cuda.FloatTensor of size 5x800 (GPU 3)]\n",
      "        (17): Parameter containing: [torch.cuda.FloatTensor of size 5 (GPU 3)]\n",
      "    )\n",
      "    (vars_bn): ParameterList(\n",
      "        (0): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (1): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (2): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (3): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (4): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (5): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (6): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "        (7): Parameter containing: [torch.cuda.FloatTensor of size 32 (GPU 3)]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 32901\n",
      "shuffle DB :train, b:10000, 5-way, 1-shot, 15-query, resize:84\n",
      "shuffle DB :test, b:100, 5-way, 1-shot, 15-query, resize:84\n",
      "step: 0 \ttraining acc: [0.2        0.4        0.44       0.47       0.46666667 0.46666667]\n",
      "step: 0 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "Test acc: [0.2075 0.3752 0.4055 0.418  0.4211 0.4229 0.4238 0.4238 0.424  0.4243\n",
      " 0.425 ]\n",
      "Test acc_adv: [0.       0.0016   0.002934 0.003866 0.0048   0.005066 0.006268 0.005867\n",
      " 0.0068   0.007065 0.007866]\n",
      "Test acc_adv_prior: [0.       0.004154 0.006886 0.00904  0.01096  0.011475 0.01412  0.01327\n",
      " 0.01527  0.0159   0.01778 ]\n",
      "step: 30 \ttraining acc: [0.16333333 0.41666667 0.44666667 0.46       0.46       0.45333333]\n",
      "step: 30 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 60 \ttraining acc: [0.20666667 0.35       0.38333333 0.41333333 0.42333333 0.42666667]\n",
      "step: 60 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 90 \ttraining acc: [0.23333333 0.37666667 0.43       0.43333333 0.44       0.43666667]\n",
      "step: 90 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 120 \ttraining acc: [0.25       0.47333333 0.52       0.52       0.52333333 0.52333333]\n",
      "step: 120 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 150 \ttraining acc: [0.16       0.38333333 0.38666667 0.40666667 0.40666667 0.42      ]\n",
      "step: 150 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 180 \ttraining acc: [0.23666667 0.3        0.32       0.33666667 0.33333333 0.34      ]\n",
      "step: 180 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 210 \ttraining acc: [0.14333333 0.45666667 0.51333333 0.52666667 0.52666667 0.53333333]\n",
      "step: 210 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 240 \ttraining acc: [0.17333333 0.40333333 0.44666667 0.46       0.47666667 0.47333333]\n",
      "step: 240 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 270 \ttraining acc: [0.23       0.39666667 0.43666667 0.45       0.44666667 0.46333333]\n",
      "step: 270 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 300 \ttraining acc: [0.12333333 0.37       0.46666667 0.5        0.48666667 0.47666667]\n",
      "step: 300 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 330 \ttraining acc: [0.21666667 0.32666667 0.38333333 0.42333333 0.43333333 0.43      ]\n",
      "step: 330 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 360 \ttraining acc: [0.13333333 0.36666667 0.44       0.44666667 0.44       0.43666667]\n",
      "step: 360 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 390 \ttraining acc: [0.18333333 0.40333333 0.47666667 0.49666667 0.48666667 0.48333333]\n",
      "step: 390 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 420 \ttraining acc: [0.19666667 0.36666667 0.4        0.41666667 0.42333333 0.42      ]\n",
      "step: 420 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 450 \ttraining acc: [0.13333333 0.35333333 0.43666667 0.47       0.48666667 0.49666667]\n",
      "step: 450 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 480 \ttraining acc: [0.24666667 0.41666667 0.47       0.47333333 0.48333333 0.48666667]\n",
      "step: 480 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "Test acc: [0.2086 0.3896 0.4172 0.4238 0.4265 0.4265 0.4282 0.429  0.429  0.4287\n",
      " 0.428 ]\n",
      "Test acc_adv: [0.       0.000933 0.002934 0.003334 0.003468 0.003866 0.00453  0.0048\n",
      " 0.004665 0.004932 0.005066]\n",
      "Test acc_adv_prior: [0.       0.00217  0.00664  0.00766  0.00794  0.00862  0.009995 0.01072\n",
      " 0.01041  0.010994 0.01122 ]\n",
      "step: 510 \ttraining acc: [0.12666667 0.47       0.50666667 0.51       0.51333333 0.51666667]\n",
      "step: 510 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 540 \ttraining acc: [0.15333333 0.41333333 0.47666667 0.5        0.51       0.50666667]\n",
      "step: 540 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 570 \ttraining acc: [0.19666667 0.37666667 0.39666667 0.41       0.41       0.41333333]\n",
      "step: 570 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 600 \ttraining acc: [0.19666667 0.41666667 0.47666667 0.48666667 0.47333333 0.47      ]\n",
      "step: 600 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 630 \ttraining acc: [0.15333333 0.36666667 0.42333333 0.43666667 0.44       0.44333333]\n",
      "step: 630 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 660 \ttraining acc: [0.11       0.33666667 0.41333333 0.42666667 0.44333333 0.44333333]\n",
      "step: 660 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 690 \ttraining acc: [0.13666667 0.4        0.44       0.43666667 0.45333333 0.46      ]\n",
      "step: 690 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 720 \ttraining acc: [0.18666667 0.37666667 0.39       0.39       0.4        0.39666667]\n",
      "step: 720 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 750 \ttraining acc: [0.21       0.44333333 0.48       0.48       0.48333333 0.49333333]\n",
      "step: 750 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 780 \ttraining acc: [0.13333333 0.36333333 0.38666667 0.40333333 0.40333333 0.4       ]\n",
      "step: 780 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 810 \ttraining acc: [0.19       0.39       0.43       0.45333333 0.45       0.45333333]\n",
      "step: 810 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 840 \ttraining acc: [0.14       0.41       0.48       0.49333333 0.49       0.49333333]\n",
      "step: 840 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 870 \ttraining acc: [0.15333333 0.39333333 0.47       0.49333333 0.51333333 0.50666667]\n",
      "step: 870 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 900 \ttraining acc: [0.16333333 0.44333333 0.47333333 0.49       0.49333333 0.49333333]\n",
      "step: 900 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 930 \ttraining acc: [0.19333333 0.46       0.51       0.53       0.53666667 0.54      ]\n",
      "step: 930 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 960 \ttraining acc: [0.13333333 0.33666667 0.42333333 0.44666667 0.44666667 0.45      ]\n",
      "step: 960 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 990 \ttraining acc: [0.18666667 0.51333333 0.57       0.58666667 0.58333333 0.57666667]\n",
      "step: 990 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "Test acc: [0.2069 0.3943 0.4258 0.433  0.4336 0.4353 0.4348 0.4355 0.4353 0.4358\n",
      " 0.435 ]\n",
      "Test acc_adv: [0.       0.0016   0.004135 0.005466 0.0072   0.007866 0.008934 0.008934\n",
      " 0.00933  0.0092   0.0096  ]\n",
      "Test acc_adv_prior: [0.      0.00418 0.00995 0.0126  0.01608 0.01765 0.01994 0.01965 0.02054\n",
      " 0.01996 0.02097]\n",
      "step: 1020 \ttraining acc: [0.21333333 0.45       0.46       0.45333333 0.45666667 0.44666667]\n",
      "step: 1020 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1050 \ttraining acc: [0.2        0.41333333 0.42666667 0.43       0.42666667 0.43      ]\n",
      "step: 1050 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1080 \ttraining acc: [0.24       0.40666667 0.40666667 0.44       0.44       0.45      ]\n",
      "step: 1080 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1110 \ttraining acc: [0.25       0.46       0.49666667 0.49666667 0.5        0.49666667]\n",
      "step: 1110 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1140 \ttraining acc: [0.22333333 0.39333333 0.42666667 0.43       0.42333333 0.43      ]\n",
      "step: 1140 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1170 \ttraining acc: [0.21666667 0.43333333 0.48333333 0.48333333 0.49       0.49      ]\n",
      "step: 1170 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1200 \ttraining acc: [0.20666667 0.46333333 0.46333333 0.48       0.48333333 0.49      ]\n",
      "step: 1200 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1230 \ttraining acc: [0.18333333 0.44       0.47       0.45666667 0.46       0.47      ]\n",
      "step: 1230 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1260 \ttraining acc: [0.25333333 0.30333333 0.31666667 0.32       0.31333333 0.31      ]\n",
      "step: 1260 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1290 \ttraining acc: [0.23666667 0.40333333 0.43       0.45       0.45       0.46      ]\n",
      "step: 1290 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1320 \ttraining acc: [0.20666667 0.4        0.43666667 0.45333333 0.44       0.44666667]\n",
      "step: 1320 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1350 \ttraining acc: [0.15666667 0.39333333 0.41333333 0.42       0.42       0.42333333]\n",
      "step: 1350 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n",
      "step: 1380 \ttraining acc: [0.16       0.32666667 0.40333333 0.42       0.42666667 0.43      ]\n",
      "step: 1380 \ttraining acc_adv: [0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import  torch, os\n",
    "import  numpy as np\n",
    "from    MiniImagenet import MiniImagenet\n",
    "import  scipy.stats\n",
    "from    torch.utils.data import DataLoader\n",
    "from    torch.optim import lr_scheduler\n",
    "import  random, sys, pickle\n",
    "import  argparse\n",
    "\n",
    "\n",
    "from MAMLMeta import Meta\n",
    "\n",
    "\n",
    "\n",
    "def mean_confidence_interval(accs, confidence=0.95):\n",
    "    n = accs.shape[0]\n",
    "    m, se = np.mean(accs), scipy.stats.sem(accs)\n",
    "    h = se * scipy.stats.t._ppf((1 + confidence) / 2, n - 1)\n",
    "    return m, h\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    torch.manual_seed(222)\n",
    "    torch.cuda.manual_seed_all(222)\n",
    "    np.random.seed(222)\n",
    "\n",
    "    print(args)\n",
    "\n",
    "    config = [\n",
    "        ('conv2d', [32, 3, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 2, 0]),\n",
    "        ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [32]),\n",
    "        ('max_pool2d', [2, 1, 0]),\n",
    "        ('flatten', []),\n",
    "        ('linear', [args.n_way, 32 * 5 * 5])\n",
    "    ]\n",
    "\n",
    "    device = torch.device('cuda:3')\n",
    "    \n",
    "    start_epoch = 0\n",
    "    start_step = 0\n",
    "    filename = 'mamleps4.pt'\n",
    "    maml = Meta(args, config).to(device)\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        start_step = checkpoint['step']\n",
    "        maml.net.load_state_dict(checkpoint['state_dict'])\n",
    "        #maml = maml.to(device)\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "    num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "    print(maml)\n",
    "    print('Total trainable tensors:', num)\n",
    "\n",
    "    # batchsz here means total episode number\n",
    "    mini = MiniImagenet('../../../dataset/', mode='train', n_way=args.n_way, k_shot=args.k_spt,\n",
    "                        k_query=args.k_qry,\n",
    "                        batchsz=10000, resize=args.imgsz)\n",
    "    mini_test = MiniImagenet('../../../dataset/', mode='test', n_way=args.n_way, k_shot=args.k_spt,\n",
    "                             k_query=args.k_qry,\n",
    "                             batchsz=100, resize=args.imgsz)\n",
    "\n",
    "    for epoch in range(args.epoch//10000):\n",
    "        # fetch meta_batchsz num of episode each time\n",
    "        db = DataLoader(mini, args.task_num, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "        for step, (x_spt, y_spt, x_qry, y_qry) in enumerate(db):\n",
    "\n",
    "            x_spt, y_spt, x_qry, y_qry = x_spt.to(device), y_spt.to(device), x_qry.to(device), y_qry.to(device)\n",
    "\n",
    "            accs, accs_adv = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "            if step % 30 == 0:\n",
    "                print('step:', step, '\\ttraining acc:', accs)\n",
    "                print('step:', step, '\\ttraining acc_adv:', accs_adv)\n",
    "                state = {'epoch': epoch, 'step': step, 'state_dict': maml.net.state_dict()}\n",
    "                torch.save(state, 'mamleps4.pt')\n",
    "\n",
    "            if step % 500 == 0:  # evaluation\n",
    "                db_test = DataLoader(mini_test, 1, shuffle=True, num_workers=0, pin_memory=True)\n",
    "                accs_all_test = []\n",
    "                accsadv_all_test = []\n",
    "                accsadvpr_all_test = []\n",
    "\n",
    "                for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                    x_spt, y_spt, x_qry, y_qry = x_spt.squeeze(0).to(device), y_spt.squeeze(0).to(device), \\\n",
    "                                                 x_qry.squeeze(0).to(device), y_qry.squeeze(0).to(device)\n",
    "\n",
    "                    accs, accs_adv, accs_adv_prior = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                    accs_all_test.append(accs)\n",
    "                    accsadv_all_test.append(accs_adv)\n",
    "                    accsadvpr_all_test.append(accs_adv_prior)\n",
    "\n",
    "                # [b, update_step+1]\n",
    "                accs = np.array(accs_all_test).mean(axis=0).astype(np.float16)\n",
    "                accs_adv = np.array(accsadv_all_test).mean(axis=0).astype(np.float16)\n",
    "                accs_adv_prior = np.array(accsadvpr_all_test).mean(axis=0).astype(np.float16)\n",
    "                print('Test acc:', accs)\n",
    "                print('Test acc_adv:', accs_adv)\n",
    "                print('Test acc_adv_prior:', accs_adv_prior)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    argparser = argparse.ArgumentParser()\n",
    "    argparser.add_argument('--epoch', type=int, help='epoch number', default=60000)\n",
    "    argparser.add_argument('--n_way', type=int, help='n way', default=5)\n",
    "    argparser.add_argument('--k_spt', type=int, help='k shot for support set', default=1)\n",
    "    argparser.add_argument('--k_qry', type=int, help='k shot for query set', default=15)\n",
    "    argparser.add_argument('--imgsz', type=int, help='imgsz', default=84)\n",
    "    argparser.add_argument('--imgc', type=int, help='imgc', default=3)\n",
    "    argparser.add_argument('--task_num', type=int, help='meta batch size, namely task num', default=4)\n",
    "    argparser.add_argument('--meta_lr', type=float, help='meta-level outer learning rate', default=1e-3)\n",
    "    argparser.add_argument('--update_lr', type=float, help='task-level inner update learning rate', default=0.01)\n",
    "    argparser.add_argument('--update_step', type=int, help='task-level inner update steps', default=5)\n",
    "    argparser.add_argument('--update_step_test', type=int, help='update steps for finetunning', default=10)\n",
    "    \n",
    "    #argparser.add_argument('--fast', action=\"store_true\", help='whether to use fgsm')\n",
    "\n",
    "    args = argparser.parse_args(args=[])\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
